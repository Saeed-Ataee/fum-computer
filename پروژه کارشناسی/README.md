## چکیده :
بیگ دیتا یا کلان داده چندسالیست که در ادبیات فناوری اطلاعات به یک اصطلاح فراگیر تبدیل شده است.معمولا ، کلان داده ها به مجموعه داده هایی گفته می شود که توانایی دریافت، اکتساب، مدیریت و پردازش آن ها در یک زمان قابل قبول به وسیله فناوری اطلاعات و ابزارهای نرم افزاری و سخت افزاری سنتی وجود ندارد.عبارت Data Big مدت ها است که برای اشاره به حجم های عظیمی از داده ها که توسط سازمان های بزرگی مانند گوگل یا ناسا ذخیره و تحلیل می شوند مورد استفاده قرار می گیرد. اما به تازگی، این عبارت بیشتر برای اشاره به مجموعه های داده ای بزرگی استفاده می شود که رشد فزاینده ی میزان داده ها به حدی است که با ابزارهای مدیریتی و پایگاه های داده سنتی و معمولی قابل مدیریت نیستند.مشکلات اصلی در کار با این نوع داده ها مربوط به برداشت و جمع آوری، ذخیره سازی، جست وجو، اشتراک گذاری، تحلیل و نمایش آن ها است. این مبحث، به این دلیل هر روز جذابیت و مقبولیت بیشتری پیدا می کند که با استفاده از تحلیل حجم های بیشتری از داده ها، می توان تحلیل های بهتر و پیشرفته تری را برای مقاصد مختلف، از جمله مقاصد تجاری، پزشکی و امنیتی، انجام داد و نتایج مناسب تری را دریافت کرد. تحقیقات در زمینه ی کلان داده ها باید روی چگونگی استخراج ارزش آن ها، چگونگی استفاده از داده ها و چگونگی تبدیل آن ها از گروهی از داده ها به کلان داده ها تمرکز کنند.
هدوپ یک فریم ورک متن باز برای ذخیره سازی امن و پردازش توزیع شده داده های حجیم می باشد، که دارای دو بخش اصلی سیستم فایل توزیع شده هدوپ و موتور پردازش نگاشت و کاهش می باشد. ساختار هدوپ برای کار با داده های بزرگ طراحی شده لذا زمانی که ما دارای فایل های کوچک کلان هستیم هدوپ نمیتواند برخورد مناسبی در مواجه با این مساله از خود نشان دهد و باعث ایجاد بار سنگین بر روی گره اصلی هدوپ و افزایش زمان پردازش نگاشت و کاهش می شود. راهکار های متفاوتی میتواند در برخورد با داده های کوچک به کار برده شود تا باعث بهبود عملکرد ذخیره سازی و پردازش و محاسبات هدوپ شود





## فهرست محتوا

فصل 1 کلان داده
===

..* 1-1تعریف	2

..* 1-2ویژگی ها	3

..* 1-3انواع داده ها	5

..* 1-4کاربرد ها	6

..* 1-5چالش ها	7

..* 1-6صنایعی که از کلان داده ها استفاده می کنند	7

فصل 2 پایگاه داده‌های NoSQL
===

..* 2-1مقدمه	10

..* 2-2مدل‌های داده‌ای در پایگاه داده‌های غیر رابطه‌ای	12

..* 2-3معیارهای گزینش پایگاه داده NoSQL	13

فصل 3 سازگاری داده‌ها در پایگاه‌داده‌های غیررابطه‌ای
===

..* 3-1تئوری CAP	17

..* 3-2ویژگی‌های ACID و BASE	19

فصل 4 ماشین مجازی
===

..* 4-1معرفی	25

..* 4-2آموزش نصب	26

فصل 5 داکر-DOCKER
===

..* 1-5 معرفی	31

..* 2-5 تفاوت آن با ماشین مجازی	32

..* 3-5 داکر برای چه کسانی مناسب است؟	32

..* 4-5 مکانیزم کاری DOCKER چگونه است؟	33

..* 5-5 داکر هاب	33

..* 6-5 کانتینر داکر	33

..* 7-5 نصب داکر بر روی اوبونتو	34

..* 8-5 استفاده از داکر برای پروژه	36

فصل 6 آپاچی هدوپ  APACHE HADOOP
===

..* 1-6 معرفی	39

..* 2-6 چرا هدوپ؟	40

..* 3-6 معماری هدوپ	40

..* 4-6 سیستم فایل توزیع شده هدوپ (HDFS)	41

..* 5-6 موتور پردازش نگاشت/کاهش	42

..* 6-6 سرویس مدیریت منابع Yarn	42

..* 7-6 سرویس‌های هدوپ	43

..* 8-6 مراحل پردازش داده‌‌ها توسط هدوپ	43

فصل 7 طریقه نصب هدوپ در اوبونتو
===

..* 1-7 مراحل نصب	45

..* 2-7 اجرای مثال Word Count با هدوپ	50

..* 3-7 استفاده از ماشین مجازی هدوپ	54

فصل 8 اکوسیستم هدوپ
===

..* 1-8 سیستم فایل توزیع شده هدوپ – HDFS	59

..* 2-8 چهارچوب مدیریت منابع YARN	60

..* 3-8 موتور پردازش MapReduce	62

..* 4-8 آپاچی ماهوت APACHE MAHOUT	62

..* 5-8 آپاچی  زو کیپر – APACHE ZOOKEEPER	64

فصل 9 آپاچی هایو  Apache Hive
===

..* 1-9 معرفی	66

..* 2-9 نصب آپاچی Hive بر روی اوبونتو	67

فصل 10 آپاچی اسپارک  APACHE SPARK
===

..* 1-10 معرفی	70

..* 2-10 نصب آپاچی اسپارک بر روی اوبونتو	71

..* 3-10 اجرای مثال WordCount	73

فصل 11 آپاچی اچ‌بیس  APACHE HBASE
===

..* 1-11 معرفی	76

..* 2-11 نصب آپاچی hbase بر روی اوبونتو	76
